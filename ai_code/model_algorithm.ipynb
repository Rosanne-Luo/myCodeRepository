{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 模型算法"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 各种采样算法"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics\n",
    "from collections import Counter\n",
    "\n",
    "from imblearn.over_sampling import RandomOverSampler, SMOTE, ADASYN\n",
    "from imblearn.under_sampling import RandomUnderSampler, NearMiss,  TomekLinks, EditedNearestNeighbours\n",
    "\n",
    "def evalute_model(X_train, X_test, y_train, y_test, model):\n",
    "    \"\"\"  使用指定指标评估模型效果\n",
    "    \n",
    "    Args:\n",
    "        X_train: 训练集特征向量\n",
    "        X_test: 测试集特征向量\n",
    "        y_train: 训练集标签\n",
    "        y_test: 测试集标签\n",
    "        model: 模型\n",
    "    \n",
    "    Return:\n",
    "        result:字典类型, 具体如下\n",
    "        result[\"accuracy\"] : 准确率\n",
    "        result['precision']: 精确率\n",
    "        result['recall']: 召回率\n",
    "        result[\"fscore\"]: f值\n",
    "        result[\"n_occurences\"]:  真实标签的数量\n",
    "        result[\"predictions_count\"]: 预测标签的数量\n",
    "        result['tp']:TP\n",
    "        result['tn']:TN\n",
    "        result['fp']:FP\n",
    "        result['auc']: AUC\n",
    "    \"\"\"\n",
    "    \n",
    "    model.fit(X_train, y_train)\n",
    "    predictions = model.predict(X_test)\n",
    "    accuracy = metrics.accuracy_score(y_test, predictions)\n",
    "    # 加上pos_label=1, average='binary' 参数可以只得到类别标签为'1'的各项参数\n",
    "    precision, recall, fscore, support = metrics.precision_recall_fscore_support(y_test, predictions) \n",
    "    tn, fp, fn, tp = metrics.confusion_matrix(y_test, predictions).ravel()\n",
    "    fpr, tpr, thresholds = metrics.roc_curve(y_test, predictions, pos_label = 1) # pos_label 指定正类标签\n",
    "    auc = metrics.auc(fpr, tpr)\n",
    "    \n",
    "    result = {'accuracy': accuracy,'precision':precision,'recall':recall,\n",
    "             'fscore':fscore, 'n_occurences':support,\n",
    "             'predictions_count': Counter(predictions),\n",
    "             'tp':tp, 'tn':tn, 'fp':fp,'fn':fn, 'auc':auc}\n",
    "    \n",
    "    return result\n",
    "    \n",
    "    \n",
    "def model_resampling_pipeline(X_train, X_test, y_train, y_test, model):\n",
    "    \"\"\" 测试各种采样方法对建模的影响\n",
    "    \n",
    "    Args:\n",
    "        X_train: 训练集特征向量\n",
    "        X_test: 测试集特征向量\n",
    "        y_train: 训练集标签向量\n",
    "        y_test: 测试集标签向量\n",
    "        model: 模型\n",
    "        \n",
    "    Return:\n",
    "        results: 结果,包含原始数据，加权数据，过采样、欠采样这四种方式处理数据后的建模结果\n",
    "    \"\"\"\n",
    "    \n",
    "    results = {'ordinary':{},\n",
    "              'class_weight':{},\n",
    "               'oversample':{},\n",
    "               'undersample':{}}\n",
    "    \n",
    "    # ------- 原始数据 ----------\n",
    "    results['ordinary'] = evalute_model(X_train, X_test, y_train, y_test, model)\n",
    "    \n",
    "    # ------- Class weight -------\n",
    "    if 'class_weight' in model.get_params().keys():\n",
    "        model.set_params(class_weight='balanced')\n",
    "        results['class_weight'] = evalute_model(X_train, X_test, y_train, y_test, model)\n",
    "    \n",
    "    # ------ OverSampling techniques -----\n",
    "    print('-------- Oversampling methods ---------')\n",
    "    #techniques = [RandomOverSampler(), SMOTE(), ADASYN()]\n",
    "    techniques = [RandomOverSampler(), SMOTE()] # ADASYN() MAC上跑不出来\n",
    "    for sampler in techniques:\n",
    "        technique = sampler.__class__.__name__\n",
    "        print(f'Technique:{technique}')\n",
    "        print(f'Before resampling: {sorted(Counter(y_train).items())}')\n",
    "        X_resampled, y_resampled = sampler.fit_sample(X_train, y_train)\n",
    "        print(f'After resampling: {sorted(Counter(y_resampled).items())}')\n",
    "        \n",
    "        results['oversample'][technique] = evalute_model(X_resampled, X_test, y_resampled, y_test, model)\n",
    "        \n",
    "    # ------ UnderSampling techniques --------\n",
    "    print('-------- Undersampling methods ---------')\n",
    "    techniques = [RandomUnderSampler(), \n",
    "                 NearMiss(version=1),\n",
    "                 NearMiss(version=2)]\n",
    "                 #TomekLinks(), MAC 跑不出来\n",
    "                # EditedNearestNeighbours()], MAC 跑不出来\n",
    "    \n",
    "    for sampler in techniques:\n",
    "        technique = sampler.__class__.__name__\n",
    "        if technique == 'NearMiss':\n",
    "            technique += str(sampler.version)\n",
    "        print(f'Technique:{technique}')\n",
    "        print(f'Before resampling: {sorted(Counter(y_train).items())}')\n",
    "        X_resampled, y_resampled = sampler.fit_sample(X_train, y_train)\n",
    "        print(f'After resampling: {sorted(Counter(y_resampled).items())}')\n",
    "        \n",
    "        results['undersample'][technique] = evalute_model(X_resampled, X_test, y_resampled, y_test, model)\n",
    "    \n",
    "    return results\n",
    "\n",
    "def evaluate_method(results, method, metrics = ['precision', 'recall', 'fscore']):\n",
    "    \"\"\" 可视化结果\n",
    "    \n",
    "    对精确率、召回率、f值、AUC值在各个采样方法下的效果进行可视化\n",
    "    \n",
    "    Args:\n",
    "        results: 结果数据，包含各种指标数据\n",
    "        method: 取值为\"oversample\", \"undersample\"\n",
    "        metrics: 度量指标，精确率，召回率，f值\n",
    "    \n",
    "    Return:\n",
    "        None\n",
    "    \"\"\"\n",
    "    fig, ax = plt.subplots(1, 7, sharey = True, figsize=(20,6)) #sharey 控制y轴属性\n",
    "    \n",
    "    for i, metric in enumerate(metrics):\n",
    "        # 绘制原始数据建模得到的指标基线\n",
    "        ax[i*2].axhline(results['ordinary'][metric][0], label = 'No Resampling')\n",
    "        ax[i*2+1].axhline(results['ordinary'][metric][1], label = 'No Resampling')\n",
    "        \n",
    "        if results['class_weight']:\n",
    "            ax[i*2].bar(0, results['class_weight'][metric][0], label = 'Adjust Class Weight')\n",
    "            ax[i*2+1].bar(0, results['class_weight'][metric][1], label = 'Adjust Class Weight')\n",
    "            \n",
    "        #ax[0].legend(loc='uppper center', bbox_to_anchor=(9,1.01),\n",
    "                   # ncol=1, fancybox=True, shadow=True)\n",
    "        ax[0].legend()\n",
    "        \n",
    "        for j, (technique, result) in enumerate(results[method].items()):\n",
    "            ax[i*2].bar(j+1, result[metric][0], label = technique)\n",
    "            ax[i*2+1].bar(j+1, result[metric][1], label = technique)\n",
    "            \n",
    "        ax[i*2].set_title(f'Alexa domain:\\n{metric}')\n",
    "        ax[i*2+1].set_title(f'DGA domain:\\n{metric}')\n",
    "        \n",
    "    # AUC\n",
    "    ax[6].set_title(f'Area under curve')\n",
    "    ax[6].axhline(results['ordinary']['auc'], label = 'No Resampling')\n",
    "    if results['class_weight']:\n",
    "        ax[6].bar(0, results['class_weight']['auc'], label='Adjust Class Weight')\n",
    "    for j, (technique, result) in enumerate(results[method].items()):\n",
    "        ax[6].bar(j+1, result['auc'], label= technique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 函数调用顺序\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "model = DecisionTreeClassifier()\n",
    "results = model_resampling_pipeline(X_train, X_test, y_train, y_test, model)\n",
    "evaluate_method(results, 'oversample')\n",
    "evaluate_method(results, 'undersample')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 定义各种模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "model_tree = DecisionTreeClassifier()\n",
    "model_rfc = RandomForestClassifier()\n",
    "model_svc = SVC()\n",
    "model_lg = LogisticRegression()\n",
    "model_knn = KNeighborsClassifier()\n",
    "model_ada = AdaBoostClassifier()\n",
    "model_mlp = MLPClassifier()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
